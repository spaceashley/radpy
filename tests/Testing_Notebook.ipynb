{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d70da6b-99c7-481b-8057-03026b333094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from radpy.stellar import *\n",
    "from radpy.datareadandformat import *\n",
    "from radpy.plotting import plot_v2_fit\n",
    "from radpy.LDfitting import initial_LDfit, run_LDfit\n",
    "from radpy.UDfitting import initial_UDfit, run_UDfit, udfit_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46006fab-a4f7-4aae-a4d6-edc9c477b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_multidatasets(fitsfile, verbose = False):\n",
    "    count = 0\n",
    "    for i, hdu in enumerate(fitsfile):\n",
    "        name = 'OI_VIS2'\n",
    "        if hdu.name == name:\n",
    "            if hdu.ver:\n",
    "                count +=1\n",
    "    if verbose:\n",
    "        print(\"Nights:\", count)\n",
    "    return count\n",
    "\n",
    "def unpack_multidatasets(fitsfile, count, verbose = False):\n",
    "    if count > 1:\n",
    "        v2_list = []\n",
    "        dv2_list = []\n",
    "        uc_list = []\n",
    "        vc_list = []\n",
    "        mjd_list = []\n",
    "        time_list = []\n",
    "        wl_list = []\n",
    "        band_list = []\n",
    "        if verbose:\n",
    "            print(\"Multiple nights\")\n",
    "        for i in range(count):\n",
    "            if verbose:\n",
    "                print(\"Version:\", i + 1)\n",
    "            v2 = fitsfile[\"OI_VIS2\", i + 1].data[\"VIS2DATA\"]\n",
    "            dv2 = fitsfile[\"OI_VIS2\", i + 1].data[\"VIS2ERR\"]\n",
    "            ucoord = fitsfile[\"OI_VIS2\", i + 1].data[\"UCOORD\"]\n",
    "            vcoord = fitsfile[\"OI_VIS2\", i + 1].data[\"VCOORD\"]\n",
    "            mjd = fitsfile[\"OI_VIS2\", i + 1].data[\"MJD\"]\n",
    "            time = fitsfile[\"OI_VIS2\", i + 1].data[\"TIME\"]\n",
    "            wl = fitsfile[\"OI_WAVELENGTH\", i + 1].data[\"EFF_WAVE\"]\n",
    "            band = fitsfile[\"OI_WAVELENGTH\", i + 1].data[\"EFF_BAND\"]\n",
    "\n",
    "            wll = [wl.tolist() for _ in range(len(v2))]\n",
    "            bandl = [band.tolist() for _ in range(len(v2))]\n",
    "\n",
    "            v2_list.append(v2)\n",
    "            dv2_list.append(dv2)\n",
    "            uc_list.append(ucoord)\n",
    "            vc_list.append(vcoord)\n",
    "            mjd_list.append(mjd)\n",
    "            time_list.append(time)\n",
    "            wl_list.append(wll)\n",
    "            band_list.append(bandl)\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        df = pd.DataFrame({'MJD': mjd_list, 'Time': time_list, 'V2': v2_list, 'V2_err': dv2_list,\n",
    "                           'Eff_wave[m]': wl_list, 'Eff_band[m]': band_list, 'UCOORD[m]': uc_list,\n",
    "                           'VCOORD[m]': vc_list})\n",
    "        df_e = df.apply(pd.Series.explode)\n",
    "        return df_e\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"Only one night.\")\n",
    "        v2 = fitsfile[\"OI_VIS2\"].data[\"VIS2DATA\"]\n",
    "        dv2 = fitsfile[\"OI_VIS2\"].data[\"VIS2ERR\"]\n",
    "        ucoord = fitsfile[\"OI_VIS2\"].data[\"UCOORD\"]\n",
    "        vcoord = fitsfile[\"OI_VIS2\"].data[\"VCOORD\"]\n",
    "        mjd = fitsfile[\"OI_VIS2\"].data[\"MJD\"]\n",
    "        time = fitsfile[\"OI_VIS2\"].data[\"TIME\"]\n",
    "        wl = fitsfile[\"OI_WAVELENGTH\"].data[\"EFF_WAVE\"]\n",
    "        band = fitsfile[\"OI_WAVELENGTH\"].data[\"EFF_BAND\"]\n",
    "\n",
    "        wl_list = [wl.tolist() for _ in range(len(v2))]\n",
    "        band_list = [band.tolist() for _ in range(len(v2))]\n",
    "\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        df = pd.DataFrame({'MJD': mjd, 'Time': time, 'V2': v2.tolist(), 'V2_err': dv2.tolist(),\n",
    "                           'Eff_wave[m]': wl_list, 'Eff_band[m]': band_list, 'UCOORD[m]': ucoord, 'VCOORD[m]': vcoord})\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "def oifits_to_pandas(filename, inst_name):\n",
    "    # Reads in an oifits file and converts into a pandas dataframe with the necessary information needed for RADPy\n",
    "    # Extracts the following data:\n",
    "    #   V2, dv2, ucoord, vcoord, mjd, time, effective wavelength, and effective bandwidth\n",
    "    # Converts the wavelengths and bandwidth arrays into lists of lists to match the V2 and V2err lists\n",
    "    # creates a dataframe\n",
    "    # Sorts the dataframe by MJD and then assigns a bracket number based on the date groupings\n",
    "    # Explodes the dataframe by extracting out each list for V2, V2_err, wavelength, and bandwidth\n",
    "    # returns the exploded, sorted, and bracket labeled df\n",
    "\n",
    "    data = fits.open(filename)\n",
    "    count = check_multidatasets(data)\n",
    "    new_df = unpack_multidatasets(data,count)\n",
    "    sorted_df = brackets(new_df, inst_name)\n",
    "    sorted_df['zipped'] = sorted_df.apply(\n",
    "        lambda row: list(zip(row['V2'], row['V2_err'], row['Eff_wave[m]'], row['Eff_band[m]'])), axis=1)\n",
    "    df_exploded = sorted_df.explode('zipped').reset_index(drop=True)\n",
    "    df_exploded[['V2', 'V2_err', 'Eff_wave[m]', 'Eff_band[m]']] = pd.DataFrame(df_exploded['zipped'].tolist(),\n",
    "                                                                               index=df_exploded.index)\n",
    "    df_exploded = df_exploded.drop(columns='zipped')\n",
    "    df_exploded['Instrument'] = [inst_name] * len(df_exploded)\n",
    "\n",
    "    return df_exploded\n",
    "\n",
    "def filename_extension(filename, inst_name, verbose=False, debug = False):\n",
    "    #########################################################################\n",
    "    # Function: filename_extension                                          #\n",
    "    # Inputs: filename -> name of data file                                 #\n",
    "    #         inst_name -> Instrument identifier                            #\n",
    "    #                      C - Classic                                      #\n",
    "    #                      P - PAVO                                         #\n",
    "    #                      V - VEGA                                         #\n",
    "    #                      M - MIRCX                                        #\n",
    "    #                      MY - MYSTIC                                      #\n",
    "    #                      S - SPICA                                        #\n",
    "    #         verbose -> default is False, if true, allows print statements #\n",
    "    # Outputs: data frame of the data with the instrument added as a column #\n",
    "    # What it does:                                                         #\n",
    "    #         1. Checks what format the file is in                          #\n",
    "    #         If .csv:                                                      #\n",
    "    #            2a. Uses pandas.read_csv to read in the file               #\n",
    "    #            3a. Adds the Instrument column                             #\n",
    "    #         If .txt:                                                      #\n",
    "    #            2b. Opens the file and reads in the first line             #\n",
    "    #            3b. Checks what delimiter the file is using                #\n",
    "    #            4b. Reads in the file                                      #\n",
    "    #            5b. Adds the instrument column                             #\n",
    "    #         If .oifits or .fits:                                          #\n",
    "    #            2c. uses the oifits_to_pandas function                     #\n",
    "    #         Returns the dataframe, and number of brackets                 #\n",
    "    #########################################################################\n",
    "\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['Instrument'] = [inst_name] * len(df)\n",
    "        sorted_df = brackets(df, inst_name)\n",
    "        num_brackets = sorted_df['Bracket'].max()\n",
    "        print('Number of brackets:', num_brackets)\n",
    "        return sorted_df, num_brackets\n",
    "        # return sorted_df\n",
    "    elif filename.endswith('.txt'):\n",
    "        header = None\n",
    "        data_start = 0\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith('#'):\n",
    "                # Remove '#' and newline, then split by pipe (or whatever header delimiter you expect)\n",
    "                header = [col.strip() for col in line.strip()[1:].split('|')]\n",
    "                data_start = i + 1\n",
    "                if debug:\n",
    "                    print(f\"Header detected: {header}\")\n",
    "                break\n",
    "\n",
    "        # Read the data lines (skip header and comments)\n",
    "        # Drop empty lines and comments\n",
    "        data_lines = [l for l in lines[data_start:] if l.strip() and not l.strip().startswith('#')]\n",
    "\n",
    "        # Save to a temp string buffer for pandas\n",
    "        from io import StringIO\n",
    "        data_str = ''.join(data_lines)\n",
    "        df = pd.read_csv(StringIO(data_str), sep=r'\\s+', header=None, engine='python')\n",
    "        if header and len(header) == df.shape[1]:\n",
    "            df.columns = header\n",
    "        df['Instrument'] = [inst_name] * len(df)\n",
    "        sorted_df = brackets(df, inst_name)\n",
    "        num_brackets = sorted_df['Bracket'].max()\n",
    "        if verbose:\n",
    "            print('Number of brackets:', num_brackets)\n",
    "        return sorted_df, num_brackets\n",
    "\n",
    "\n",
    "    elif filename.endswith('.oifits') or filename.endswith('.fits'):\n",
    "        df = oifits_to_pandas(filename, inst_name)\n",
    "        num_brackets = df['Bracket'].max()\n",
    "        print('Number of brackets:', num_brackets)\n",
    "        return df, num_brackets\n",
    "        # return df\n",
    "\n",
    "    else:\n",
    "        header = None\n",
    "        data_start = 0\n",
    "        with open(filename, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith('#'):\n",
    "                # Remove '#' and newline, then split by pipe (or whatever header delimiter you expect)\n",
    "                header = [col.strip() for col in line.strip()[1:].split('|')]\n",
    "                data_start = i + 1\n",
    "            if debug:\n",
    "                print(f\"Header detected: {header}\")\n",
    "            break\n",
    "\n",
    "        # Read the data lines (skip header and comments)\n",
    "        # Drop empty lines and comments\n",
    "        data_lines = [l for l in lines[data_start:] if l.strip() and not l.strip().startswith('#')]\n",
    "\n",
    "        # Save to a temp string buffer for pandas\n",
    "        from io import StringIO\n",
    "        data_str = ''.join(data_lines)\n",
    "        df = pd.read_csv(StringIO(data_str), sep=r'\\s+', header=None, engine='python')\n",
    "        if header and len(header) == df.shape[1]:\n",
    "            df.columns = header\n",
    "        df['Instrument'] = [inst_name] * len(df)\n",
    "        sorted_df = brackets(df, inst_name)\n",
    "        num_brackets = sorted_df['Bracket'].max()\n",
    "        if verbose:\n",
    "            print('Number of brackets:', num_brackets)\n",
    "        return sorted_df, num_brackets\n",
    "\n",
    "def brackets(df, instrument):\n",
    "    # bracket generator\n",
    "    # PAVO brackets are assigned via same baseline\n",
    "    # Classic has no brackets\n",
    "    # MIRCX/MYSTIC/SPICA are by MJD\n",
    "    # Vega is uncertain for now but will be date im fairly certain\n",
    "    if instrument == 'M' or instrument == 'm':\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        sorted_df = df.sort_values(by='MJD')\n",
    "        sorted_df['Bracket'] = sorted_df.groupby('MJD').ngroup() + 1\n",
    "        return sorted_df\n",
    "    if instrument == 'P' or instrument == 'p':\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        sorted_df = df.sort_values(by='U(meters)')\n",
    "        sorted_df['Bracket'] = sorted_df.groupby('U(meters)').ngroup() + 1\n",
    "        return sorted_df\n",
    "    if instrument == 'C' or instrument == 'c':\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        df['Bracket'] = [1] * len(df)\n",
    "        return df\n",
    "    if instrument == 'S' or instrument == 's':\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        sorted_df = df.sort_values(by='UCOORD[m]')\n",
    "        sorted_df['Bracket'] = sorted_df.groupby('UCOORD[m]').ngroup() + 1\n",
    "        return sorted_df\n",
    "    if instrument == 'My' or instrument == 'my':\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        sorted_df = df.sort_values(by='MJD')\n",
    "        sorted_df['Bracket'] = sorted_df.groupby('MJD').ngroup() + 1\n",
    "        return sorted_df\n",
    "    if instrument == 'V' or instrument == 'v':\n",
    "        pd.set_option('display.float_format', '{:.12f}'.format)\n",
    "        sorted_df = df.sort_values(by='MJD')\n",
    "        sorted_df['Bracket'] = sorted_df.groupby('MJD').ngroup() + 1\n",
    "        return sorted_df\n",
    "\n",
    "\n",
    "def combined(*dfs, fulldf=False):\n",
    "    # combines the data into one big data frame if needed\n",
    "\n",
    "    b = pd.concat([df['B'] for df in dfs], ignore_index=True)\n",
    "    v2 = pd.concat([df['V2'] for df in dfs], ignore_index=True)\n",
    "    dv2 = pd.concat([df['dV2'] for df in dfs], ignore_index=True)\n",
    "    wave = pd.concat([df['Wave'] for df in dfs], ignore_index=True)\n",
    "    band = pd.concat([df['Band'] for df in dfs], ignore_index=True)\n",
    "    brack = pd.concat([df['Bracket'] for df in dfs], ignore_index=True)\n",
    "    inst = pd.concat([df['Instrument'] for df in dfs], ignore_index=True)\n",
    "\n",
    "\n",
    "    if not fulldf:\n",
    "        return b, v2, dv2, wave, band, brack, inst\n",
    "\n",
    "    if fulldf:\n",
    "        return pd.DataFrame({\n",
    "            'B': b, 'V2': v2, 'dV2': dv2,\n",
    "            'Wave': wave, 'Band': band,\n",
    "            'Bracket': brack, 'Instrument': inst})\n",
    "\n",
    "\n",
    "class InterferometryData:\n",
    "    def __init__(self, df, instrument_code):\n",
    "        self.raw = df.copy()\n",
    "        self.instrument = instrument_code.lower()\n",
    "        self.cleaned = None\n",
    "        self.process()\n",
    "\n",
    "    def process(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement the .process() method\")\n",
    "\n",
    "    def make_df(self, LDC=None):\n",
    "        n = len(self.B)\n",
    "\n",
    "        if LDC is None:\n",
    "            ldc_col = [None] * n\n",
    "        elif np.isscalar(LDC):\n",
    "            ldc_col = [LDC] * n\n",
    "        elif isinstance(LDC, (list, np.ndarray, pd.Series)) and len(LDC) == n:\n",
    "            ldc_col = LDC\n",
    "        else:\n",
    "            raise ValueError(f\"LDC must be None, a scalar, or a list/array of length {n}, got {LDC}.\")\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"B\": self.B,\n",
    "            \"V2\": self.V2,\n",
    "            \"dV2\": self.dV2,\n",
    "            \"Wave\": self.Wave,\n",
    "            \"LDC\": ldc_col,\n",
    "            \"Band\": self.Band,\n",
    "            \"Bracket\": self.Bracket,\n",
    "            \"Instrument\": [self.instrument] * len(self.B)\n",
    "\n",
    "        })\n",
    "\n",
    "    def make_ldmcdf(self, LDC):\n",
    "        # spf = self.B / self.Wave\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            # \"Spf\":spf,\n",
    "            \"B\": self.B,\n",
    "            \"V2\": self.V2,\n",
    "            \"dV2\": self.dV2,\n",
    "            \"LDC\": LDC,\n",
    "            \"Bracket\": self.Bracket,\n",
    "            \"Instrument\": [self.instrument] * len(self.V2)\n",
    "        })\n",
    "\n",
    "\n",
    "class PavoData(InterferometryData):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df, instrument_code='p')\n",
    "\n",
    "    def process(self):\n",
    "        df = self.raw.dropna(subset=['V2', 'sigma_V2'])\n",
    "        self.cleaned = df\n",
    "\n",
    "        self.V2 = df['V2']\n",
    "        self.dV2 = df['sigma_V2']\n",
    "        self.U = df['U(meters)']\n",
    "        self.V = df['V(meters)']\n",
    "        self.B = np.sqrt(self.U ** 2 + self.V ** 2)\n",
    "        self.Wave = self.B / df['B/lambda']\n",
    "        self.Band = pd.Series(np.full(len(df), 5e-9))  # 5 nm\n",
    "        self.Bracket = df['Bracket']\n",
    "\n",
    "\n",
    "class ClassicData(InterferometryData):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df, instrument_code='c')\n",
    "\n",
    "    def process(self):\n",
    "        df = self.raw.dropna(subset=['Vis', 'Vis_e'])  # clean NaNs\n",
    "        self.cleaned = df\n",
    "        v = df['Vis']\n",
    "        dv = df['Vis_e']\n",
    "\n",
    "        self.B = df['B']\n",
    "        self.V2 = v ** 2\n",
    "        self.dV2 = self.V2 * np.sqrt(2 * (dv / v) ** 2)\n",
    "        self.Wave = pd.Series(np.full(len(self.B), 2.1329e-6))  # meters\n",
    "        self.Band = pd.Series(np.full(len(self.B), 5e-9))  # meters (5 nm)\n",
    "        self.Bracket = df['Bracket']\n",
    "\n",
    "\n",
    "class VegaData(InterferometryData):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df, instrument_code='v')\n",
    "\n",
    "    def process(self):\n",
    "        df = self.raw.dropna(subset=['V2', 'sigma_sys', 'sigma_stat'])  # clean NaNs\n",
    "        self.cleaned = df\n",
    "        dv2_sys = df['sigma_sys']\n",
    "        dv2_stat = df['sigma_stat']\n",
    "\n",
    "        self.B = df['Baseline length']\n",
    "        self.V2 = df['V2']\n",
    "        self.dV2 = np.sqrt((dv2_sys ** 2) + (dv2_stat) ** 2)\n",
    "        self.Wave = df['lambda'] * 1e-9\n",
    "        self.Band = pd.Series(np.full(len(df), 5e-9))\n",
    "        self.Bracket = df['Bracket']\n",
    "\n",
    "\n",
    "class MircxData(InterferometryData):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df, instrument_code='m')\n",
    "\n",
    "    def process(self):\n",
    "        df = self.raw.dropna(subset=['V2', 'V2_err'])  # clean NaNs\n",
    "        self.cleaned = df\n",
    "\n",
    "        ucoord = (df['UCOORD[m]'].values).astype('float')\n",
    "        vcoord = (df['VCOORD[m]'].values).astype('float')\n",
    "        self.B = np.sqrt((ucoord ** 2) + (vcoord ** 2))\n",
    "        self.V2 = df['V2']\n",
    "        self.dV2 = df['V2_err']\n",
    "        self.Wave = df['Eff_wave[m]']\n",
    "        self.Band = df['Eff_band[m]']\n",
    "        self.Bracket = df['Bracket']\n",
    "\n",
    "class MysticData(InterferometryData):\n",
    "    def __init__(self, df):\n",
    "        super().__init__(df, instrument_code='my')\n",
    "\n",
    "    def process(self):\n",
    "        df = self.raw.dropna(subset=['V2', 'V2_err'])  # clean NaNs\n",
    "        self.cleaned = df\n",
    "\n",
    "        ucoord = (df['UCOORD[m]'].values).astype('float')\n",
    "        vcoord = (df['VCOORD[m]'].values).astype('float')\n",
    "        self.B = np.sqrt((ucoord ** 2) + (vcoord ** 2))\n",
    "        self.V2 = df['V2']\n",
    "        self.dV2 = df['V2_err']\n",
    "        self.Wave = df['Eff_wave[m]']\n",
    "        self.Band = df['Eff_band[m]']\n",
    "        self.Bracket = df['Bracket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "128b1c4c-92a9-4494-9cd6-bed3f8d16a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from radpy.plotting import bin_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "from radpy.UDfitting import UDV2\n",
    "from radpy.LDfitting import V2\n",
    "plt.rcParams['text.usetex'] = True\n",
    "def plot_v2_fit(data_dict, star, line_spf=None, ldc_band=None, eq_text=False,\n",
    "                datasets_to_plot=None, plot_ldmodel=False, plot_udmodel=False,\n",
    "                to_bin=None, title=None, set_axis = None, savefig=None, show=True):\n",
    "    ###########################################################################\n",
    "    # Function: plot_v2_fit                                                   #\n",
    "    # Inputs: data_dict -> dict of InterferometryData objects,                #\n",
    "    #                    e.g. {'pavo': pavo_obj, ...}                         #\n",
    "    #         star-> star object with .theta and .ldc* attributes             #\n",
    "    #                (ldcR, ldcK, etc.), and .V2(line_spf, theta, ldc)        #\n",
    "    #         line_spf -> x values for model curve                            #\n",
    "    #         ldc_band -> string (e.g. \"ldcR\", \"ldcK\") for which LDC          #\n",
    "    #                     coefficient to use                                  #\n",
    "    #         eq_text -> optional string for annotation                       #\n",
    "    #         datasets_to_plot-> list of keys in data_dict to plot            #\n",
    "    #                            (default: all)                               #\n",
    "    #         plot_ldmodel-> bool, whether to plot the ld model curve         #\n",
    "    #         plot_udmodel -> bool, whether to plot the ud model curve        #\n",
    "    #         to_bin -> list of kets in data_dict to bin                      #\n",
    "    #         set_axis -> sets the axis limits                                #\n",
    "    #         title -> allows user to set a plot title                        #\n",
    "    #         savefig-> filename to save, if desired                          #\n",
    "    #         show-> whether to plt.show()                                    #\n",
    "    # Outputs: the plot                                                       #\n",
    "    # What it does:                                                           #\n",
    "    #        1. Initializes plotting parameters                               #\n",
    "    #        2. Checks to see what datasets the user wants plotted            #\n",
    "    #        3. Defines dictionaries for each instrument and the marker,      #\n",
    "    #           color, label, and alpha value for each one                    #\n",
    "    #        4. Checks to see if set_axis has been assigned. If it has,       #\n",
    "    #           sets the axis limits and adjusts line_spf accordingly. If     #\n",
    "    #           not, sets line_spf to be max(spf) with padding                #\n",
    "    #        Starts with the top plot                                         #\n",
    "    #        5. For each data set, sets the keys for the color, marker, label #\n",
    "    #           and alpha value                                               #\n",
    "    #        6. Checks to see if the to_bin has been set                      #\n",
    "    #        7. if to_bin has been set, plots the unbinned data for each      #\n",
    "    #           data set, and then bins the data sets indicated then plots    #\n",
    "    #           those                                                         #\n",
    "    #        8. If to_bin has not been set, it plots the unbinned data        #\n",
    "    #        9. For the model, if plot_ldmodel is set, pulls the ldtheta,     #\n",
    "    #           error on the theta, and the ldcs and calculates the fits for  #\n",
    "    #           the relevant filter                                           #\n",
    "    #       10. Plots the model for the filter indicated                      #\n",
    "    #       11. If eq_text is set, annotates the plot with the theta val      #\n",
    "    #       12. If plot_udmodel is set, pulls the udtheta and error, and      #\n",
    "    #           calculates the UD model and plots it                          #\n",
    "    #       13. If eq_text is set, annotates the plot the theta val           #\n",
    "    #       14. Checks to see how many datasets are being plotted. If more    #\n",
    "    #           than 1, sets the legend. If not, does not plot legend.        #\n",
    "    #       Bottom plot:                                                      #\n",
    "    #       15. For each data set, it pulls the respective keys for the       #\n",
    "    #           color, label, alpha, and marker for each instrument           #\n",
    "    #       16. For each data set, checks to see if the to_bin value has been #\n",
    "    #           set.                                                          #\n",
    "    #       17. If plot_ldmodel has been set, it calculates the residuals for #\n",
    "    #           the data and the model for the filter indicated.              #\n",
    "    #       18. If to_bin has been set, it calculates the residuals for the   #\n",
    "    #           binned data as well.                                          #\n",
    "    #       19. If plot_udmodel has been set, it calculates the residuals for #\n",
    "    #           the data and the ud model.                                    #\n",
    "    #       20. If to_bin has been set, it calcualtes the residuals for the   #\n",
    "    #           binned data as well.                                          #\n",
    "    #       21. Plots the residuals for the unbinned (and binned if set)      #\n",
    "    #       22. Saves fig if save_fig has been set                            #\n",
    "    #       23. Shows fig if show has been set.                               #\n",
    "    ###########################################################################\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "    f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [10, 3]}, sharex=True)\n",
    "\n",
    "    if datasets_to_plot is None:\n",
    "        datasets_to_plot = list(data_dict.keys())\n",
    "\n",
    "    color_map = {\n",
    "        'pavo': '#02ccfe',\n",
    "        'classic': '#738595',\n",
    "        'vega': '#5edc1f',\n",
    "        'mircx': '#efc8ff',\n",
    "        'mystic': '#ffcfdc',\n",
    "        'spica': '#ff964f'\n",
    "    }\n",
    "    binned_color_map = {\n",
    "        'pavo': '#030aa7',\n",
    "        'classic': '#000000',\n",
    "        'vega': '#028f1e',\n",
    "        'mircx': '#7e1e9c',\n",
    "        'mystic': '#ff028d',\n",
    "        'spica': '#fe4b03'\n",
    "    }\n",
    "    marker_map = {\n",
    "        'pavo': '.',\n",
    "        'classic': 's',\n",
    "        'vega': '^',\n",
    "        'mircx': 'x',\n",
    "        'mystic': '*',\n",
    "        'spica': 'D'\n",
    "    }\n",
    "    label_map = {\n",
    "        'pavo': r'$\\rm PAVO$',\n",
    "        'classic': r'$\\rm Classic$',\n",
    "        'vega': r'$\\rm VEGA$',\n",
    "        'mircx': r'$\\rm MIRC-X$',\n",
    "        'mystic': r'$\\rm MYSTIC$',\n",
    "        'spica': r'$\\rm SPICA$'\n",
    "    }\n",
    "    alpha_map = {\n",
    "        'pavo': 0.25,\n",
    "        'classic': 0.25,\n",
    "        'vega': 0.25,\n",
    "        'mircx': 0.15,\n",
    "        'mystic': 0.15,\n",
    "        'spica': 0.15\n",
    "    }\n",
    "\n",
    "    if set_axis and line_spf is None:\n",
    "        xmin = set_axis[0]\n",
    "        xmax = set_axis[1]\n",
    "        ymin = set_axis[2]\n",
    "        ymax = set_axis[3]\n",
    "        a0.set_xlim(xmin, xmax)\n",
    "        a0.set_ylim(ymin, ymax)\n",
    "        line_spf = np.linspace(0.00001, xmax, 1000)\n",
    "    else:\n",
    "        all_spf = []\n",
    "        for key in datasets_to_plot:\n",
    "            data = data_dict[key]\n",
    "            spf = np.array(data.B) / np.array(data.Wave)\n",
    "            all_spf.extend(spf)\n",
    "        all_spf = np.array(all_spf)\n",
    "        max_spf = np.max(all_spf)\n",
    "        line_spf = np.linspace(0.00001, max_spf * 1.1, 1000)  # slight padding\n",
    "\n",
    "    # --- Top: V2 ---\n",
    "    for key in datasets_to_plot:\n",
    "        data = data_dict[key]\n",
    "        color = color_map.get(key, None)\n",
    "        bin_color = binned_color_map.get(key, None)\n",
    "        marker = marker_map.get(key, '.')\n",
    "        label = label_map.get(key, key.capitalize())\n",
    "        alpha = alpha_map.get(key, 0.5)\n",
    "        spf = np.array(data.B) / np.array(data.Wave)\n",
    "\n",
    "        is_binned = to_bin and key in to_bin\n",
    "        # Always plot both, but only one gets the label\n",
    "        if is_binned:\n",
    "            # Plot unbinned points, no label\n",
    "            a0.plot(spf, data.V2, linestyle='None', marker=marker, markersize=3, color=color, alpha=alpha)\n",
    "            a0.errorbar(spf, data.V2, yerr=abs(data.dV2), fmt=marker, markersize=3, linestyle='None', linewidth=0.5,\n",
    "                        color=color,\n",
    "                        capsize=3, alpha=alpha)\n",
    "            # Plot binned points, with label\n",
    "            binned_spf, binned_v2, binned_dv2 = bin_data(spf, data.V2, data.dV2)\n",
    "            a0.plot(binned_spf, binned_v2, linestyle='None', marker=marker, markersize=7, color=bin_color, label=label)\n",
    "            a0.errorbar(binned_spf, binned_v2, yerr=abs(binned_dv2), fmt=marker, linestyle='None', markersize=7,\n",
    "                        color=bin_color,\n",
    "                        capsize=3)\n",
    "        else:\n",
    "            # Plot unbinned points, with label\n",
    "            a0.plot(spf, data.V2, linestyle='None', marker=marker, markersize=3, color=color, alpha=alpha, label=label)\n",
    "            a0.errorbar(spf, data.V2, yerr=abs(data.dV2), fmt=marker, markersize=3, linestyle='None', linewidth=0.5,\n",
    "                        color=color,\n",
    "                        capsize=3, alpha=alpha)\n",
    "    # --- Model ---\n",
    "    if plot_ldmodel:\n",
    "        ldc_value = getattr(star, ldc_band, None)\n",
    "        theta = getattr(star, \"ldtheta\", None)\n",
    "        dtheta = getattr(star, \"ldtheta_err\", None)\n",
    "        if ldc_value is not None and theta is not None:\n",
    "            model_label = fr\"$ \\rm Model ({ldc_band.replace('ldc_', '').upper()})$\"\n",
    "            a0.plot(line_spf, V2(line_spf, theta, ldc_value), '--', color='black', label=model_label)\n",
    "            if eq_text:\n",
    "                eq1 = fr\"$\\theta_{{\\rm LD}} = {round(theta, 3)} \\pm {round(dtheta, 3)} \\rm ~mas$\"\n",
    "                a0.text(0.05, 0.05, eq1, transform=a0.transAxes, color='black', fontsize=15)\n",
    "        else:\n",
    "            print(f\"Warning: {ldc_band} or ldtheta not present for star, skipping model plot.\")\n",
    "\n",
    "    if plot_udmodel:\n",
    "        theta = getattr(star, \"udtheta\", None)\n",
    "        dtheta = getattr(star, \"udtheta_err\", None)\n",
    "        if theta is not None:\n",
    "            model_label = fr\"$\\rm Uniform~Disk~Model$\"\n",
    "            a0.plot(line_spf, UDV2(line_spf, theta), '--', color='black', label=model_label)\n",
    "            if eq_text:\n",
    "                eq1 = fr\"$\\theta_{{\\rm UD}} = {round(theta, 3)} \\pm {round(dtheta, 3)} \\rm ~mas$\"\n",
    "                a0.text(0.05, 0.05, eq1, transform=a0.transAxes, color='black', fontsize=15)\n",
    "        else:\n",
    "            print(f\"Warning: udtheta not present for star, skipping model plot.\")\n",
    "\n",
    "    if len(datasets_to_plot) > 1:\n",
    "        a0.legend(fontsize=12)\n",
    "\n",
    "    a0.set_ylabel(r'$V^2$', labelpad=17)\n",
    "    a0.tick_params(axis='x', labelbottom=False)\n",
    "    a0.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    a0.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    a0.set_title(title)\n",
    "\n",
    "    # --- Bottom panel: Residuals ---\n",
    "    for key in datasets_to_plot:\n",
    "        data = data_dict[key]\n",
    "        color = color_map.get(key, None)\n",
    "        bin_color = binned_color_map.get(key, None)\n",
    "        marker = marker_map.get(key, '.')\n",
    "        alpha = alpha_map.get(key, 0.5)\n",
    "        spf = np.array(data.B) / np.array(data.Wave)\n",
    "\n",
    "        is_binned = to_bin and key in to_bin  # e.g. to_bin = ['pavo']\n",
    "\n",
    "        # --- Model and Residuals for Unbinned ---\n",
    "        if plot_ldmodel and ldc_value is not None and theta is not None:\n",
    "            model_v2 = V2(spf, theta, ldc_value)\n",
    "            residuals = np.array(data.V2) - model_v2\n",
    "            a1.plot(spf, residuals, linestyle='None', marker=marker, markersize=3, color=color, alpha=alpha)\n",
    "            a1.errorbar(spf, residuals, yerr=abs(data.dV2), fmt=marker, markersize=3, linestyle='None', linewidth=0.5,\n",
    "                        color=color,\n",
    "                        capsize=3, alpha=alpha)\n",
    "\n",
    "            # --- Model and Residuals for Binned ---\n",
    "            if is_binned:\n",
    "                binned_spf, binned_v2, binned_dv2 = bin_data(spf, data.V2, data.dV2)\n",
    "                model_binv2 = V2(binned_spf, theta, ldc_value)\n",
    "                binned_res = binned_v2 - model_binv2\n",
    "                a1.plot(binned_spf, binned_res, linestyle='None', marker=marker, markersize=7, color=bin_color)\n",
    "                a1.errorbar(binned_spf, binned_res, yerr=abs(binned_dv2), fmt=marker, linestyle='None', markersize=7,\n",
    "                            color=bin_color, capsize=3)\n",
    "\n",
    "        # --- (Repeat similar for UD model if desired) ---\n",
    "        if plot_udmodel and theta is not None:\n",
    "            model_udv2 = UDV2(spf, theta)\n",
    "            ud_res = np.array(data.V2) - model_udv2\n",
    "            a1.plot(spf, ud_res, linestyle='None', marker=marker, markersize=3, color=color, alpha=alpha)\n",
    "            a1.errorbar(spf, ud_res, yerr=abs(data.dV2), fmt=marker, markersize=3, linestyle='None', linewidth=0.5,\n",
    "                        color=color, capsize=5,\n",
    "                        alpha=alpha)\n",
    "\n",
    "            if is_binned:\n",
    "                binned_spf, binned_v2, binned_dv2 = bin_data(spf, data.V2, data.dV2)\n",
    "                model_binudv2 = UDV2(binned_spf, theta)\n",
    "                binned_udres = binned_v2 - model_binudv2\n",
    "                a1.plot(binned_spf, binned_udres, linestyle='None', marker=marker, markersize=7, color=bin_color)\n",
    "                a1.errorbar(binned_spf, binned_udres, yerr=abs(binned_dv2), fmt=marker, linestyle='None', markersize=7,\n",
    "                            color=bin_color, capsize=3)\n",
    "\n",
    "    a1.axhline(y=0, color='black', linestyle='--')\n",
    "    a1.set_ylabel(r'$\\rm Residual$', labelpad=3)\n",
    "    plt.yticks([-.25, 0, 0.25])\n",
    "    a1.set_ylim([-0.35, 0.35])\n",
    "    a1.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    a1.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.xlabel(r'$\\rm Spatial$ $\\rm frequency$ [$\\rm rad^{-1}$]')\n",
    "\n",
    "    if savefig:\n",
    "        f.savefig(savefig, bbox_inches='tight')\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return f, (a0, a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "704c2e81-62db-45b6-91cf-8be63030e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lmfit import Model\n",
    "import scipy.special as ss\n",
    "from astropy.stats import mad_std\n",
    "from radpy.stellar import temp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Using UFloat objects with std_dev==0 may give unexpected results.\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"DataFrameGroupBy.apply operated on the grouping columns\")\n",
    "#Uniform disk V2 equation\n",
    "def UDV2(sf, theta):\n",
    "    x = np.pi*sf*(theta/(206265*1000))\n",
    "    vis = (2*ss.jv(1,x))/x\n",
    "    return vis**2\n",
    "##########################################################################################\n",
    "#Uniform disk V2 equation with scaling factor added in\n",
    "def scaledUDV2(sf, theta, V0):\n",
    "    x = np.pi*sf*(theta/(206265*1000))\n",
    "    vis = (V0**2)*(((2*ss.jv(1,x))/x)**2)\n",
    "    return vis\n",
    "##########################################################################################\n",
    "# calculates chi squared and chi squared reduced\n",
    "def chis(y, exp_y, yerr, dof):\n",
    "    chisqr = np.sum(((y - exp_y) / (yerr)) ** 2)\n",
    "    chisqr_red = chisqr / (len(y) - dof)\n",
    "    return chisqr, chisqr_red\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# Weighted average function\n",
    "def weight_avg(df):\n",
    "    x = df['V2']\n",
    "    dx = df['dV2']\n",
    "    weight = 1 / (dx ** 2)\n",
    "    wavg = sum(weight * x) / sum(weight)\n",
    "    dwavg = 1 / np.sqrt(sum(weight))\n",
    "    return dwavg\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# Random bracket function for bootstrapping\n",
    "def random_bracket(df, num_of_brackets):\n",
    "    ###########################################################################\n",
    "    # Function: random_bracket                                                #\n",
    "    # Inputs: df -> dataframe with spatial frequency, v2, v2_err, and bracket #\n",
    "    #         num_of_brackets -> number of brackets in total you have         #\n",
    "    # Outputs: spf_br -> the spatial frequencies randomized                   #\n",
    "    #          v2_br -> the visibility squared randomized                     #\n",
    "    #          dv2_br -> the error on the v2 randomized                       #\n",
    "    #          wavgs -> weighted averages of the v2                           #\n",
    "    # What it does:                                                           #\n",
    "    #      1. sets the seed                                                   #\n",
    "    #      2. picks a random number between 2 and the number of brackets      #\n",
    "    #      3. Selects that many unique bracket labels at random               #\n",
    "    #      4. Filters the dataframe down to only those with those specific    #\n",
    "    #         bracket labels                                                  #\n",
    "    #      5. Groups by the bracket labels                                    #\n",
    "    #      6. Applies the weight average to the grouped data                  #\n",
    "    #      7. Adds the weighted average as a column in the data frame         #\n",
    "    #      8. Merges the groups into a new group for weighted average         #\n",
    "    #         based on the bracket                                            #\n",
    "    #      9. Splits up the dataframe into spatial frequency, v2, dv2, and    #\n",
    "    #         wavg                                                            #\n",
    "    #     10. Returns spatial frequency, v2, dv2, and wavg                    #\n",
    "    ###########################################################################\n",
    "    np.random.seed()\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    dydata = []\n",
    "    numbr = np.random.randint(2, num_of_brackets)\n",
    "    # chatgpt wrote the next couple lines\n",
    "    random_group_ids = df['Bracket'].drop_duplicates().sample(n=numbr).values\n",
    "\n",
    "    # Filter the DataFrame for the selected groups\n",
    "    random_groups = df[df['Bracket'].isin(random_group_ids)]\n",
    "\n",
    "    grouped = random_groups.groupby('Bracket')\n",
    "\n",
    "    # results = grouped.apply(weight_avg, include_group = False).reset_index()\n",
    "    results = grouped.apply(weight_avg).reset_index()\n",
    "    # Version-aware apply for future compatibility\n",
    "    # pandas_major = int(pd.__version__.split('.')[0])\n",
    "    # pandas_minor = int(pd.__version__.split('.')[1])\n",
    "    # if pandas_major >= 2:\n",
    "    #    results = grouped.apply(weight_avg, include_group=False).reset_index()\n",
    "    # else:\n",
    "    #    results = grouped.apply(weight_avg).reset_index()\n",
    "\n",
    "    results.columns = ['Bracket', 'Wavg']\n",
    "    random_groups_with_avg = random_groups.merge(results, on='Bracket')\n",
    "\n",
    "    spf_br = random_groups_with_avg['Spf']  # spatial frequency in rad^-1\n",
    "    v2_br = random_groups_with_avg['V2']  # Visibility squared\n",
    "    dv2_br = random_groups_with_avg['dV2']\n",
    "    wavgs = random_groups_with_avg['Wavg']\n",
    "\n",
    "    return spf_br, v2_br, dv2_br, wavgs\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# Percent difference function\n",
    "def percent_diff(x1, x2, verbose=False):\n",
    "    diff = (abs(x1 - x2) / ((x1 + x2) / 2)) * 100\n",
    "    if verbose:\n",
    "        print(\"Percent difference:\", round(diff, 2), \"%\")\n",
    "    return round(diff, 3)\n",
    "##########################################################################################\n",
    "def safe_theta_extraction(result):\n",
    "    param = result.params['theta']\n",
    "    value = param.value\n",
    "    stderr = param.stderr\n",
    "    if stderr is None or stderr == 0:\n",
    "        return value, None\n",
    "    else:\n",
    "        uvar = result.uvars['theta']\n",
    "        return uvar.n, uvar.s\n",
    "##########################################################################################\n",
    "def safe_thetaV0_extraction(result):\n",
    "    tparam = result.params['theta']\n",
    "    tvalue = tparam.value\n",
    "    tstderr = tparam.stderr\n",
    "    vparam = result.params['V0']\n",
    "    vvalue = vparam.value\n",
    "    vstderr = vparam.stderr\n",
    "    if tstderr is None or tstderr == 0 or vstderr is None or vstderr == 0:\n",
    "        return tvalue, None, vvalue, None\n",
    "    else:\n",
    "        uvar = result.uvars['theta']\n",
    "        vvar = result.uvars['V0']\n",
    "        return uvar.n, uvar.s, vvar.n, vvar.s\n",
    "##########################################################################################\n",
    "def initial_UDfit(spf, v2, dv2, theta_guess, star_params, v0_flag = False, verbose=False):\n",
    "    #####################################################################\n",
    "    # Function: initial_UDfit                                           #\n",
    "    # Inputs: spf -> spatial frequency                                  #\n",
    "    #         v2 -> visibilitity squared                                #\n",
    "    #         dv2 -> error on the V2                                    #\n",
    "    #         theta_guess -> initial guess for theta                    #\n",
    "    #         star_params -> stellar class object                       #\n",
    "    #         verbose -> if set to True, allows print statements        #\n",
    "    #                    defaults to False                              #\n",
    "    # Outputs: theta_ilm -> initial uniform disk diameter               #\n",
    "    #          dtheta_ilm -> error on the diameter                      #\n",
    "    #          chisqr_ilm -> chi squared reduced value                  #\n",
    "    # What it does:                                                     #\n",
    "    #        1. Initialized the model                                   #\n",
    "    #        2. initializes the parameters                              #\n",
    "    #        3. Fits for the UD diameter using lmfit                    #\n",
    "    #           uses for the weights as 1/dv2                           #\n",
    "    #        4. pulls out the theta, dtheta, and chi squared reduced    #\n",
    "    #        5. updates the stellar object                              #\n",
    "    #        6. Returns the theta, dtheta, and chi squared reduced      #\n",
    "    #####################################################################\n",
    "    if not v0_flag:\n",
    "        print(\"No scaling used\")\n",
    "        udmodel = Model(UDV2)\n",
    "        udparams = udmodel.make_params(theta=theta_guess)\n",
    "        ud_result = udmodel.fit(v2, udparams, sf=spf, weights=1 / (dv2), scale_covar=False)\n",
    "        theta_ilm, dtheta_ilm = safe_theta_extraction(ud_result)\n",
    "\n",
    "        chisqr_ilm = ud_result.redchi  # chi squared reduced of the fit\n",
    "        if verbose:\n",
    "            print('Initial fit with lmfit:')\n",
    "            print(ud_result.fit_report())\n",
    "\n",
    "        star_params.update(udthetai=round(theta_ilm,5), udthetai_err=round(dtheta_ilm,5))\n",
    "        return (theta_ilm, dtheta_ilm, chisqr_ilm)\n",
    "        \n",
    "    if v0_flag:\n",
    "        print(\"Scaling used\")\n",
    "        udmodel = Model(scaledUDV2)\n",
    "        udparams = udmodel.make_params(theta=theta_guess, V0 = 1.0)\n",
    "        ud_result = udmodel.fit(v2, udparams, sf=spf, weights=1 / (dv2), scale_covar=False)\n",
    "        theta_ilm, dtheta_ilm, v0_ilm, dv0_ilm = safe_thetaV0_extraction(ud_result)\n",
    "        chisqr_ilm = ud_result.redchi  # chi squared reduced of the fit\n",
    "        \n",
    "        if verbose:\n",
    "            print('Initial fit with lmfit:')\n",
    "            print(ud_result.fit_report())\n",
    "\n",
    "        star_params.update(udthetai=round(theta_ilm,5), udthetai_err=round(dtheta_ilm,5), udv0i = round(v0_ilm), udv0i_err = round(dv0_ilm))\n",
    "        return (theta_ilm, dtheta_ilm, v0_ilm, dv0_ilm, chisqr_ilm) \n",
    "\n",
    "def make_df(B, v2, dv2, wave, band, brack, inst, fulldf=False):\n",
    "    rand_wave = np.random.normal(wave, band)\n",
    "    new_spf = B / rand_wave\n",
    "    if not fulldf:\n",
    "        return new_spf\n",
    "    if fulldf:\n",
    "        new_df = pd.DataFrame(np.column_stack((new_spf, v2, dv2, brack, inst)),\n",
    "                              columns=['Spf', 'V2', 'dV2', 'Bracket', 'Instrument'])\n",
    "        return new_df\n",
    "\n",
    "def bootstrap(df, inst):\n",
    "    ###########################################################\n",
    "    # Function: bootstrap                                     #\n",
    "    # Inputs: df -> the data dataframe                        #\n",
    "    #         inst -> the intstrument                         #\n",
    "    # Outputs: the new_df                                     #\n",
    "    # What it does:                                           #\n",
    "    #       1. If the instrument is set to c (Classic),       #\n",
    "    #          samples the V2 on a normal distribution        #\n",
    "    #          and creates a new dataframe with that.         #\n",
    "    #       2. If the instrument is any others, determines    #\n",
    "    #          the number of brackets in the dataset.         #\n",
    "    #       3. calls the random_bracket function              #\n",
    "    #       4. samples the V2 on a normal distribution        #\n",
    "    #       5. creates a new dataframe with that              #\n",
    "    #       6. Returns the new dataframe                      #\n",
    "    ###########################################################\n",
    "    if inst == 'c' or inst == 'C':\n",
    "        newv2 = np.random.normal(df['V2'], df['dV2'])\n",
    "        new_df = pd.DataFrame(np.column_stack((df['Spf'], newv2, df['dV2'])), columns=['Spf', 'V2', 'dV2'])\n",
    "        return new_df\n",
    "    else:\n",
    "        num_brackets = df['Bracket'].max()\n",
    "        spfbr, v2br, dv2br, avgdv2 = random_bracket(df, num_brackets)\n",
    "        newv2 = np.random.normal(v2br, avgdv2)\n",
    "        new_df = pd.DataFrame(np.column_stack((spfbr, newv2, dv2br)), columns=['Spf', 'V2', 'dV2'])\n",
    "        return new_df\n",
    "\n",
    "\n",
    "def udfit(df, stellar_params, v0_flag = False, verbose=False):\n",
    "    #####################################################################\n",
    "    # Function: udfit                                                   #\n",
    "    # Inputs: df -> dataframe with data in it                           #\n",
    "    #         star_params -> stellar class object                       #\n",
    "    #         verbose -> if set to True, allows print statements        #\n",
    "    #                    defaults to False                              #\n",
    "    # Outputs: theta_ud -> initial uniform disk diameter                #\n",
    "    # What it does:                                                     #\n",
    "    #        1. Initialized the model                                   #\n",
    "    #        2. initializes the parameters                              #\n",
    "    #        3. Fits for the UD diameter using lmfit                    #\n",
    "    #           uses for the weights as 1/dv2                           #\n",
    "    #        4. pulls out the theta                                     #\n",
    "    #        5. Returns the theta                                       #\n",
    "    #####################################################################\n",
    "    if not v0_flag:\n",
    "        print(\"No scaling used\")\n",
    "        udmodel = Model(UDV2)\n",
    "        ud_params = udmodel.make_params(theta=stellar_params.udthetai)\n",
    "        ud_result = udmodel.fit(df['V2'], ud_params, sf=df['Spf'], weights=1 / (df['dV2']), scale_covar=True)\n",
    "        theta_ud = ud_result.uvars['theta'].n\n",
    "        return ((theta_ud))\n",
    "    if v0_flag:\n",
    "        print(\"Scaling used\")\n",
    "        udmodel = Model(scaledUDV2)\n",
    "        ud_params = udmodel.make_params(theta=stellar_params.udthetai, V0 = stellar_params.udv0i)\n",
    "        ud_result = udmodel.fit(df['V2'], ud_params, sf=df['Spf'], weights=1 / (df['dV2']), scale_covar=True)\n",
    "        theta_ud = ud_result.uvars['theta'].n\n",
    "        v0_ud = ud_result.uvars['V0'].n\n",
    "        return ((theta_ud, v0_ud))\n",
    "\n",
    "\n",
    "def run_UDfit(mc_num, bs_num, datasets, stellar_params, v0_flag = False, verbose=False):\n",
    "    ######################################################################\n",
    "    # Function: run_udmcbs_fit                                           #\n",
    "    # Inputs: mc_num -> number of Monte Carlo iterations                 #\n",
    "    #         bs_num -> number of bootstrap iterations                   #\n",
    "    #         datasets -> the datasets you want fit                      #\n",
    "    #                     format: [inst1, inst2, inst3]                  #\n",
    "    #         stellar_params -> star object                              #\n",
    "    #         verbose -> if True, allows print statements                #\n",
    "    #                    default is False                                #\n",
    "    # Outputs: UD -> a list of all the uniform disk diameters calculated #\n",
    "    #                during the fitting routine                          #\n",
    "    # What it does:                                                      #\n",
    "    #      1. Initializes the empty list for the diameters               #\n",
    "    #      2. If verbose is set, it initializes the empty lists for      #\n",
    "    #         spf, v2, and dv2                                           #\n",
    "    #      3. enters the Monte Carlo loop                                #\n",
    "    #      4. Creates the dataframes for each dataset                    #\n",
    "    #      5. For each dataframe, samples the wavelength of observation  #\n",
    "    #         on a normal distribution. Then calculates new spatial      #\n",
    "    #         frequencies                                                #\n",
    "    #      6. Enters the bootstrapping loop                              #\n",
    "    #      7. Pulls the instrument for each data set                     #\n",
    "    #      8. Calls the bootstrap function with the instrument's df and  #\n",
    "    #         the instrument ID                                          #\n",
    "    #      9. appends the output of the bootstrap function to a list.    #\n",
    "    #     10. Concatenates all the dataframes created in the bootstrap   #\n",
    "    #         loop.                                                      #\n",
    "    #     11. Calculates the uniform disk diameter with udfit            #\n",
    "    #     12. Appends the diameter to the list called UD.                #\n",
    "    #     13. After the loops, returns the UD.                           #\n",
    "    ######################################################################\n",
    "    UD = []\n",
    "    V0 = []\n",
    "    if verbose:\n",
    "        udmcbs_spf = []\n",
    "        udmcbs_v2 = []\n",
    "        udmcbs_dv2 = []\n",
    "\n",
    "    for _ in range(mc_num):\n",
    "        dfs = [d.make_df() for d in datasets]\n",
    "\n",
    "        for df in dfs:\n",
    "            df['Spf'] = df['B'] / np.random.normal(df['Wave'], df['Band'])\n",
    "\n",
    "        for _ in range(bs_num):\n",
    "            bs_dfs = []\n",
    "\n",
    "            for df in dfs:\n",
    "                inst = df[\"Instrument\"].iloc[0]\n",
    "                # print('Instrument:', inst)\n",
    "                boot_df = bootstrap(df, inst)\n",
    "                bs_dfs.append(boot_df)\n",
    "\n",
    "            new_df = pd.concat(bs_dfs, ignore_index=True)\n",
    "            if not v0_flag:\n",
    "                print(\"No scaling used\")\n",
    "                results = udfit(new_df, stellar_params, v0_flag, verbose)\n",
    "                UD.append(results)\n",
    "                if verbose:\n",
    "                    udmcbs_spf.append(new_df['Spf'])\n",
    "                    udmcbs_v2.append(new_df['V2'])\n",
    "                    udmcbs_dv2.append(new_df['dV2'])\n",
    "                    return UD, udmcbs_spf, udmcbs_v2, udmcbs_dv2\n",
    "            if v0_flag:\n",
    "                print(\"Scaling used\")\n",
    "                results = udfit(new_df, stellar_params,v0_flag, verbose)\n",
    "                UD.append(results[0])\n",
    "                V0.append(results[1])\n",
    "                if verbose:\n",
    "                    udmcbs_spf.append(new_df['Spf'])\n",
    "                    udmcbs_v2.append(new_df['V2'])\n",
    "                    udmcbs_dv2.append(new_df['dV2'])\n",
    "                    return UD, V0, udmcbs_spf, udmcbs_v2, udmcbs_dv2\n",
    "    if not v0_flag:\n",
    "        print(\"No scaling used\")\n",
    "        return (UD)\n",
    "    if v0_flag:\n",
    "        print(\"Scaling used\")\n",
    "        return (UD, V0)\n",
    "\n",
    "\n",
    "def udfit_values(x, y, dy, mc_results, stellar_params, v0_flag = False, verbose=False):\n",
    "    ################################################################\n",
    "    # Function: udfit_values                                       #\n",
    "    # Inputs: x -> the spatial frequencies                         #\n",
    "    #         y -> the V2                                          #\n",
    "    #        dy -> the error on the V2                             #\n",
    "    #        UD -> the list of diameters                           #\n",
    "    #        stellar_params -> the star object                     #\n",
    "    #        verbose - > if true, returns print statements         #\n",
    "    # Outputs: None                                                #\n",
    "    # What it does:                                                #\n",
    "    #     1. Takes the mean of the uniform disk diameter list      #\n",
    "    #     2. Takes the median absolute deviation of the UDs        #\n",
    "    #     3. Calculates the chi squared and chi squared reduced    #\n",
    "    #        of the uniform disk diameter fit.                     #\n",
    "    #     4. Calculates the effective temperature using the mean   #\n",
    "    #     5. Updates the stellar object with the new parameters    #\n",
    "    ################################################################\n",
    "    if not v0_flag:\n",
    "        UD = mc_results\n",
    "        avg_UD = np.mean(UD)\n",
    "        std_UD = mad_std(UD)\n",
    "\n",
    "        chisq, chisqr = chis(y, UDV2(x, avg_UD), y, 1)\n",
    "        teff_ud = temp(stellar_params.fbol, stellar_params.fbol_err, avg_UD, std_UD)\n",
    "\n",
    "        stellar_params.update(teff=round(teff_ud[0],5), teff_err=round(teff_ud[1],5), udtheta=round(avg_UD,5), udtheta_err=round(std_UD,5))\n",
    "        if verbose:\n",
    "            print('Uniform Disk Diameter after MC/BS:', round(avg_UD, 4), '+/-', round(std_UD, 5), 'mas')\n",
    "            print(\"Chi-squared:\", round(chisq, 3))\n",
    "            print(\"Chi-squared reduced:\", round(chisqr,3))\n",
    "            print(\"Temperature:\", round(teff_ud[0], 1), \"+/-\", round(teff_ud[1], 1), \"K\")\n",
    "    if v0_flag:\n",
    "        UD = mc_results[0]\n",
    "        V0 = mc_results[1]\n",
    "        avg_UD = np.mean(UD)\n",
    "        std_UD = mad_std(UD)\n",
    "        avg_V0 = np.mean(V0)\n",
    "        std_V0 = np.std(V0)\n",
    "        chisq, chisqr = chis(y, UDV2(x, avg_UD), y, 2)\n",
    "        teff_ud = temp(stellar_params.fbol, stellar_params.fbol_err, avg_UD, std_UD)\n",
    "        stellar_params.update(teff=round(teff_ud[0],5), teff_err=round(teff_ud[1],5), udtheta=round(avg_UD,5), udtheta_err=round(std_UD,5), udv02 = round(avg_V0**2, 5), udv02_err = round(std_V0**2, 5))\n",
    "        if verbose:\n",
    "            print('Uniform Disk Diameter after MC/BS:', round(avg_UD, 4), '+/-', round(std_UD, 5), 'mas')\n",
    "            print('V0^2:', round(avg_V0**2, 5), '+/-', round(std_V0**2, 5))\n",
    "            print(\"Chi-squared:\", round(chisq, 3))\n",
    "            print(\"Chi-squared reduced:\", round(chisqr,3))\n",
    "            print(\"Temperature:\", round(teff_ud[0], 1), \"+/-\", round(teff_ud[1], 1), \"K\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ab3b6-65b0-4c5c-9ae2-9cd14abcd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lmfit import Model\n",
    "import concurrent.futures\n",
    "import scipy.special as ss\n",
    "from radpy.stellar import temp\n",
    "from astropy.stats import mad_std\n",
    "from radpy.UDfitting import chis, weight_avg, percent_diff, safe_theta_extraction\n",
    "from radpy.limbdarkcoeffs import ldc_calc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Using UFloat objects with std_dev==0 may give unexpected results.\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"DataFrameGroupBy.apply operated on the grouping columns\")\n",
    "#Limb-darkened disk V2 equation\n",
    "def V2(sf, theta, mu):\n",
    "    #mu = 0.7039725\n",
    "    alpha = 1-mu\n",
    "    beta = mu\n",
    "    x = np.pi*sf*(theta/(206265*1000))\n",
    "    vis = (((alpha/2)+(beta/3))**(-2))*((alpha*(ss.jv(1,x)/x))+ beta*(np.sqrt(np.pi/2)*(ss.jv(3/2,x)/(x**(3/2)))))**2\n",
    "    return vis\n",
    "##########################################################################################\n",
    "# Random bracket function for bootstrapping for limb-darkening\n",
    "def random_bracket_ld(df, num_of_brackets):\n",
    "    ###########################################################################\n",
    "    # Function: random_bracket                                                #\n",
    "    # Inputs: df -> dataframe with spatial frequency, v2, v2_err, and bracket #\n",
    "    #         num_of_brackets -> number of brackets in total you have         #\n",
    "    # Outputs: spf_br -> the spatial frequencies randomized                   #\n",
    "    #          v2_br -> the visibility squared randomized                     #\n",
    "    #          dv2_br -> the error on the v2 randomized                       #\n",
    "    #          ldc_br -> the limb-darkening coefficients\n",
    "    #          wavgs -> weighted averages of the v2                           #\n",
    "    # What it does:                                                           #\n",
    "    #      1. sets the seed                                                   #\n",
    "    #      2. picks a random number between 2 and the number of brackets      #\n",
    "    #      3. Selects that many unique bracket labels at random               #\n",
    "    #      4. Filters the dataframe down to only those with those specific    #\n",
    "    #         bracket labels                                                  #\n",
    "    #      5. Groups by the bracket labels                                    #\n",
    "    #      6. Applies the weight average to the grouped data                  #\n",
    "    #      7. Adds the weighted average as a column in the data frame         #\n",
    "    #      8. Merges the groups into a new group for weighted average         #\n",
    "    #         based on the bracket                                            #\n",
    "    #      9. Splits up the dataframe into spatial frequency, v2, dv2, ldcs,  #\n",
    "    #         and wavg                                                        #\n",
    "    #     10. Returns spatial frequency, v2, dv2, and wavg                    #\n",
    "    ###########################################################################\n",
    "    np.random.seed()\n",
    "    xdata = []\n",
    "    ydata = []\n",
    "    dydata = []\n",
    "    ldcdata = []\n",
    "    numbr = np.random.randint(2, num_of_brackets)\n",
    "    # chatgpt wrote the next couple lines\n",
    "    random_group_ids = df['Bracket'].drop_duplicates().sample(n=numbr).values\n",
    "\n",
    "    # Filter the DataFrame for the selected groups\n",
    "    random_groups = df[df['Bracket'].isin(random_group_ids)]\n",
    "\n",
    "    grouped = random_groups.groupby('Bracket')\n",
    "    results = grouped.apply(weight_avg).reset_index()\n",
    "    results.columns = ['Bracket', 'Wavg']\n",
    "    random_groups_with_avg = random_groups.merge(results, on='Bracket')\n",
    "\n",
    "    spf_br = random_groups_with_avg['Spf']  # spatial frequency in rad^-1\n",
    "    v2_br = random_groups_with_avg['V2']  # Visibility squared\n",
    "    dv2_br = random_groups_with_avg['dV2']\n",
    "    ldc_br = random_groups_with_avg['LDC']\n",
    "    wavgs = random_groups_with_avg['Wavg']\n",
    "\n",
    "    return spf_br, v2_br, dv2_br, ldc_br, wavgs\n",
    "\n",
    "##########################################################################################\n",
    "def initial_LDfit(spf, v2, dv2, star_params, filt, verbose=False):\n",
    "    #####################################################################\n",
    "    # Function: initial_LDfit                                           #\n",
    "    # Inputs: spf -> spatial frequency                                  #\n",
    "    #         v2 -> visibilitity squared                                #\n",
    "    #         dv2 -> error on the V2                                    #\n",
    "    #         theta_guess -> initial guess for theta                    #\n",
    "    #         star_params -> stellar class object                       #\n",
    "    #         verbose -> if set to True, allows print statements        #\n",
    "    #                    defaults to False                              #\n",
    "    # Outputs: ldtheta_ilm -> initial uniform disk diameter             #\n",
    "    #          lddtheta_ilm -> error on the diameter                    #\n",
    "    #          chisqr_ldilm -> chi squared reduced value                #\n",
    "    # What it does:                                                     #\n",
    "    #        1. Calculates the temperature using the initial UD         #\n",
    "    #        2. Calculated the LDC                                      #\n",
    "    #        3. Initialized the model                                   #\n",
    "    #        4. initializes the parameters                              #\n",
    "    #        5. Fits for the UD diameter using lmfit                    #\n",
    "    #           uses for the weights as 1/dv2                           #\n",
    "    #        6. pulls out the theta, dtheta, and chi squared reduced    #\n",
    "    #        7. updates the stellar object                              #\n",
    "    #        8. Returns the theta, dtheta, and chi squared reduced      #\n",
    "    #####################################################################\n",
    "    t, dt = temp(star_params.fbol, star_params.fbol_err, star_params.udthetai, star_params.udthetai_err)\n",
    "    ldc = ldc_calc(t, star_params.logg, star_params.feh, filt)\n",
    "\n",
    "    ldmodel = Model(V2, independent_vars=['sf', 'mu'])\n",
    "    ldparams = ldmodel.make_params(theta=star_params.udthetai)\n",
    "    ld_result = ldmodel.fit(v2, ldparams, sf=spf, mu=ldc, weights= 1 / (dv2), scale_covar=False)\n",
    "    ldtheta_ilm, lddtheta_ilm = safe_theta_extraction(ld_result)\n",
    "    chisqr_ldilm = ld_result.redchi  # chi squared reduced of the fit\n",
    "\n",
    "    star_params.update(ldthetai=round(ldtheta_ilm,5), ldthetai_err = round(lddtheta_ilm,5), teff=round(t,5), teff_err=round(dt,5))\n",
    "    if verbose:\n",
    "        print(\"Effective temperature:\", round(t,5), \"+/-\", round(dt,5), \"K\")\n",
    "        print(\"LDC for filter \", filt, \":\", round(ldc,5))\n",
    "        print('Initial fit with lmfit:')\n",
    "        print(ld_result.fit_report())\n",
    "\n",
    "    return ldtheta_ilm, lddtheta_ilm, chisqr_ldilm\n",
    "\n",
    "\n",
    "def bootstrap_ld(df, inst):\n",
    "    ###########################################################\n",
    "    # Function: bootstrap_ld                                  #\n",
    "    # Inputs: df -> the data dataframe                        #\n",
    "    #         inst -> the intstrument                         #\n",
    "    # Outputs: the new_df                                     #\n",
    "    # What it does:                                           #\n",
    "    #       1. If the instrument is set to c (Classic),       #\n",
    "    #          samples the V2 on a normal distribution        #\n",
    "    #          and creates a new dataframe with that.         #\n",
    "    #       2. If the instrument is any others, determines    #\n",
    "    #          the number of brackets in the dataset.         #\n",
    "    #       3. calls the random_bracket function              #\n",
    "    #       4. samples the V2 on a normal distribution        #\n",
    "    #       5. creates a new dataframe with that              #\n",
    "    #       6. Returns the new dataframe                      #\n",
    "    ###########################################################\n",
    "    if inst == 'c' or inst == 'C':\n",
    "        newv2 = np.random.normal(df['V2'], df['dV2'])\n",
    "        new_df = pd.DataFrame(np.column_stack((df['Spf'], newv2, df['dV2'], df['LDC'])),\n",
    "                              columns=['Spf', 'V2', 'dV2', 'LDC'])\n",
    "        return new_df\n",
    "    else:\n",
    "        num_brackets = df['Bracket'].max()\n",
    "        spfbr, v2br, dv2br, ldcbr, avgdv2 = random_bracket_ld(df, num_brackets)\n",
    "        newv2 = np.random.normal(v2br, avgdv2)\n",
    "        new_df = pd.DataFrame(np.column_stack((spfbr, newv2, dv2br, ldcbr)), columns=['Spf', 'V2', 'dV2', 'LDC'])\n",
    "        return new_df\n",
    "\n",
    "\n",
    "def ldfit(df, stellar_params, verbose=False):\n",
    "    #####################################################################\n",
    "    # Function: ldfit                                                   #\n",
    "    # Inputs: df -> dataframe with data in it                           #\n",
    "    #         star_params -> stellar class object                       #\n",
    "    #         verbose -> if set to True, allows print statements        #\n",
    "    #                    defaults to False                              #\n",
    "    # Outputs: theta_ld -> initial uniform disk diameter                #\n",
    "    # What it does:                                                     #\n",
    "    #        1. Initialized the model                                   #\n",
    "    #        2. initializes the parameters                              #\n",
    "    #        3. Fits for the LD diameter using lmfit                    #\n",
    "    #           uses for the weights as 1/dv2                           #\n",
    "    #        4. pulls out the theta                                     #\n",
    "    #        5. Returns the theta                                       #\n",
    "    #####################################################################\n",
    "    ldmodel = Model(V2, independent_vars=['sf', 'mu'])\n",
    "    ld_params = ldmodel.make_params(theta=stellar_params.udtheta)\n",
    "    ld_result = ldmodel.fit(df['V2'], ld_params, sf=df['Spf'], mu=df['LDC'], weights=1 / (df['dV2']), scale_covar=True)\n",
    "    theta_ld, _ = safe_theta_extraction(ld_result)\n",
    "    #theta_ld = ld_result.uvars['theta'].n\n",
    "\n",
    "    return theta_ld\n",
    "\n",
    "\n",
    "def ldfit_values(x, y, dy, LD, ldcs, stellar_params, verbose=False):\n",
    "    ##################################################################\n",
    "    # Function: ldfit_values                                         #\n",
    "    # Inputs: x -> the spatial frequencies                           #\n",
    "    #         y -> the V2                                            #\n",
    "    #        dy -> the error on the V2                               #\n",
    "    #        LD -> the list of diameters                             #\n",
    "    #        ldcs -> limb darkening coefficients                     #\n",
    "    #        stellar_params -> the star object                       #\n",
    "    #        verbose - > if true, returns print statements           #\n",
    "    # Outputs: avg_LD -> average limb darkened diameter              #\n",
    "    #          std_LD -> the median absolute deviation of LD theta   #\n",
    "    #          teff_ld[0] -> effective temperature                   #\n",
    "    #          teff_ld[1] -> error on the effective temperature      #\n",
    "    #          ldc_results -> the ldc for each band                  #\n",
    "    #          chisq_results -> the chi square and chi square red    #\n",
    "    #                           values for each ldc band             #\n",
    "    # What it does:                                                  #\n",
    "    #     1. Takes the mean of the limb-darkened disk diameters      #\n",
    "    #     2. Takes the median absolute deviation of the LDs          #\n",
    "    #     3. Calculates the effective temperature using the mean     #\n",
    "    #     4. Initializes the ldc_results and chisq_results           #\n",
    "    #        to store dynamically                                    #\n",
    "    #     5. For each band in the ldcs, calculates the V2 model      #\n",
    "    #     6. Calculates the chi squared and chi squared reduced      #\n",
    "    #        for each LDC band                                       #\n",
    "    #     7. Stores the results in the ldc_results and chisq_results #\n",
    "    #     8. Returns the avg_LD, std_LD, teff and teff error, the    #\n",
    "    #        ldc results, and the chi squared results                #\n",
    "    ##################################################################\n",
    "    avg_LD = np.mean(LD)\n",
    "    std_LD = mad_std(LD)\n",
    "    teff_ld = temp(stellar_params.fbol, stellar_params.fbol_err, avg_LD, std_LD)\n",
    "    # Store results dynamically\n",
    "    ldc_results = {}\n",
    "    chisq_results = {}\n",
    "\n",
    "    for band in ldcs:\n",
    "        ldc_val = ldcs[band]\n",
    "        if ldc_val is not None:\n",
    "            model_v2 = V2(x, avg_LD, ldc_val)\n",
    "            chisq, chisqr = chis(y, model_v2, dy, 1)\n",
    "            ldc_results[band] = ldc_val\n",
    "            chisq_results[band] = {\"chisq\": chisq, \"chisqr\": chisqr}\n",
    "\n",
    "    if verbose:\n",
    "        print('Limb-darkened Disk Diameter after MC/BS:', round(avg_LD, 4), '+/-', round(std_LD, 5), 'mas')\n",
    "        for band, ldc_val in ldc_results.items():\n",
    "            print(f\"Limb-darkening coefficient in {band}:\", round(ldc_val, 5))\n",
    "            print(f\"Chi-squared for {band} band:\", round(chisq_results[band][\"chisq\"], 3))\n",
    "            print(f\"Reduced chi-squared for {band} band:\", round(chisq_results[band][\"chisqr\"], 3))\n",
    "        print(\"Temperature:\", round(teff_ld[0], 1), \"+/-\", round(teff_ld[1], 1), \"K\")\n",
    "\n",
    "    return avg_LD, std_LD, teff_ld[0], teff_ld[1], ldc_results, chisq_results\n",
    "\n",
    "\n",
    "def mcbs_worker(args):\n",
    "    #############################################################\n",
    "    # Function: mcbs_worker                                     #\n",
    "    # Inputs: args -> the mc_dfs, the bs_num, stellar_params,   #\n",
    "    #                 and verbose                               #\n",
    "    # Outputs: the limb darkened disk list                      #\n",
    "    # What it does:                                             #\n",
    "    #       1. unpacks the arguments                            #\n",
    "    #       2. Initializes the limb-darkened disk list          #\n",
    "    #       3. Enters the bootstrap loop                        #\n",
    "    #       4. For each dataframe created in the Monte Carlo    #\n",
    "    #          loop, it determines which instrument, then       #\n",
    "    #          calls the bootstrap function for the ld          #\n",
    "    #       5. Appends the resulting dataframe to the list      #\n",
    "    #       6. Concatenates all the bootstrapped dfs into one   #\n",
    "    #       7. Calls ldfit and fits for the limb-darkened theta #\n",
    "    #       8. Appends results to the LD list                   #\n",
    "    #       9. Returns the LD list                              #\n",
    "    #############################################################\n",
    "\n",
    "    mc_dfs, bs_num, stellar_params, verbose = args\n",
    "    LD = []\n",
    "    for _ in range(bs_num):\n",
    "        bs_dfs = []\n",
    "        for df in mc_dfs:\n",
    "            inst = df[\"Instrument\"].iloc[0]\n",
    "            boot_df = bootstrap_ld(df, inst)\n",
    "            bs_dfs.append(boot_df)\n",
    "        new_df = pd.concat(bs_dfs, ignore_index=True)\n",
    "        theta_ldbs = ldfit(new_df, stellar_params, verbose)\n",
    "        LD.append(theta_ldbs)\n",
    "    return LD\n",
    "\n",
    "\n",
    "def run_LDfit(mc_num, bs_num, ogdata, datasets, stellar_params, verbose=False, debug=False):\n",
    "    ######################################################################\n",
    "    # Function: run_ldmcbs_fit_parallel                                  #\n",
    "    # Inputs: mc_num -> number of Monte Carlo iterations                 #\n",
    "    #         bs_num -> number of bootstrap iterations                   #\n",
    "    #         ogdata -> original data sets                               #\n",
    "    #         datasets -> the datasets you want fit                      #\n",
    "    #                     format: [inst1, inst2, inst3]                  #\n",
    "    #         stellar_params -> star object                              #\n",
    "    #         verbose -> if True, allows print statements                #\n",
    "    #                    default is False                                #\n",
    "    #         debug -> allows debug statements to show                   #\n",
    "    #                  default is set to False                           #\n",
    "    # Outputs: theta_ld-> final limb-darkened disk diameter              #\n",
    "    #          dtheta_ld -> error on the ld diameter                     #\n",
    "    #          T -> effective temperature                                #\n",
    "    #          dT -> error on the effective temperature                  #\n",
    "    #          final_ldcs -> the final ldcs for each detected band       #\n",
    "    #          final_chisqrs -> the final chi square and chi square      #\n",
    "    #                           reduced values                           #\n",
    "    # What it does:                                                      #\n",
    "    #      1. Initializes a filter map dictionary relating each          #\n",
    "    #         instrument to a filter                                     #\n",
    "    #      2. sets the T_new to be the current temperature in the star   #\n",
    "    #         object                                                     #\n",
    "    #      3. sets an arbitrary number for the diff_teff and diff_theta  #\n",
    "    #      4. sets the minimum percent difference                        #\n",
    "    #      5. unpacks the ogdata for comparison later                    #\n",
    "    #      6. Starts the while loop that compares the percent difference #\n",
    "    #         between the theta and teff of the iteration before and the #\n",
    "    #         theta and teff of the current iteration                    #\n",
    "    #      7. Initializes the empty list for the diameters and a         #\n",
    "    #         dynamic list for the ldcs per filter                       #\n",
    "    #      8. For each data set, it calculates a ldc depending on the    #\n",
    "    #         instrument                                                 #\n",
    "    #      9. enters the Monte Carlo loop                                #\n",
    "    #     10. Creates the dataframes for each dataset                    #\n",
    "    #     11. For each dataframe, it samples the ldc on a normal         #\n",
    "    #         distribution.\n",
    "    #     12. For each dataframe, samples the wavelength of observation  #\n",
    "    #         on a normal distribution. Then calculates new spatial      #\n",
    "    #         frequencies                                                #\n",
    "    #     13. Begins running all the bootstrapping loops in parallel     #\n",
    "    #         by calling mcbs_worker                                     #\n",
    "    #     14. Appends each result of the mcbs_worked to the LD list      #\n",
    "    #     15. Resets the while loop iterators                            #\n",
    "    #     16. Calcualtes a new LD theta, LD dtheta, teff and dteff by    #\n",
    "    #         calling ldfit_values                                       #\n",
    "    #     17. Updates the stellar object                                 #\n",
    "    #     18. Calculates the new percent difference for theta and teff   #\n",
    "    #     19. After the final iteration of the while loop,               #\n",
    "    #         calls ldfit_values to do a final fit for the theta, theta  #\n",
    "    #         error, teff, teff error, ldc_values, and chi-square vals   #\n",
    "    #     20. Updates stellar object with the ldc values for each filter #\n",
    "    #     21. Calculates final percent differences for teff and theta    #\n",
    "    #     22. Returns final theta, theta err, teff, teff error, ldc_vals #\n",
    "    #         and chi-sqr vals.                                          #\n",
    "    ######################################################################\n",
    "    filter_map_i = {\n",
    "        'p': 'R',\n",
    "        'v': 'R',\n",
    "        'c': 'K',\n",
    "        'm': 'H',\n",
    "        'my': 'K',\n",
    "        's': 'R'\n",
    "        # Add other instruments as needed\n",
    "    }\n",
    "    T_new = stellar_params.teff\n",
    "    theta_new = stellar_params.udtheta\n",
    "    diff_theta = 5\n",
    "    diff_teff = 5\n",
    "    min_percent = 0.05\n",
    "    iter = 0\n",
    "    x = ogdata[0]\n",
    "    y = ogdata[1]\n",
    "    dy = ogdata[2]\n",
    "    while diff_theta >= min_percent or diff_teff >= min_percent:\n",
    "        LD = []\n",
    "        ldc_per_filter = {}\n",
    "        for d in datasets:\n",
    "            inst = d.instrument.lower()\n",
    "            filt = filter_map_i[inst]\n",
    "            if filt not in ldc_per_filter:\n",
    "                ldc_val = ldc_calc(stellar_params.teff,\n",
    "                                   stellar_params.logg,\n",
    "                                   stellar_params.feh, filt)\n",
    "                ldc_per_filter[filt] = ldc_val\n",
    "\n",
    "        mc_args = []\n",
    "        for _ in range(mc_num):\n",
    "            mc_dfs = []\n",
    "            for d in datasets:\n",
    "                inst = d.instrument.lower()\n",
    "                filt = filter_map_i[inst]\n",
    "                mu = np.random.normal(ldc_per_filter[filt], 0.02)\n",
    "                df = d.make_df(LDC=mu)\n",
    "                df['Spf'] = df['B'] / np.random.normal(df['Wave'], df['Band'])\n",
    "                mc_dfs.append(df)\n",
    "            mc_args.append((mc_dfs, bs_num, stellar_params, verbose))\n",
    "\n",
    "        # Parallel execute\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            results = list(executor.map(mcbs_worker, mc_args))\n",
    "            for res in results:\n",
    "                LD.extend(res)\n",
    "\n",
    "        T_old = T_new\n",
    "        theta_old = theta_new\n",
    "        theta_new, _, T_new, _, _, _ = ldfit_values(x, y, dy, LD, ldc_per_filter, stellar_params, verbose=debug)\n",
    "        stellar_params.update(teff=round(T_new,5), ldtheta=round(theta_new,5))\n",
    "        diff_teff = percent_diff(T_old, T_new, verbose=debug)\n",
    "        diff_theta = percent_diff(theta_old, theta_new, verbose=debug)\n",
    "        iter += 1\n",
    "    if verbose:\n",
    "        print(\"Final Values after \", iter, \" iterations:\")\n",
    "    theta_ld, dtheta_ld, T, dT, final_ldcs, final_chis = ldfit_values(x, y, dy, LD, ldc_per_filter, stellar_params,\n",
    "                                                                      verbose)\n",
    "    stellar_params.update(teff=round(T,5), ldtheta=round(theta_ld,5), ldtheta_err=round(dtheta_ld,5))\n",
    "    for filt, mu in final_ldcs.items():\n",
    "        setattr(stellar_params, f\"ldc_{filt}\", round(mu, 5))\n",
    "    diff_teff = percent_diff(T_old, T_new, verbose)\n",
    "    diff_theta = percent_diff(theta_old, theta_new, verbose)\n",
    "\n",
    "    return theta_ld, dtheta_ld, T, dT, final_ldcs, final_chis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "301bf78c-a026-45f0-8ba6-f9f91f116697",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenamec = \"C:\\\\Users\\\\oxfor\\\\Research\\\\rsadpy\\\\tests\\\\test_data\\\\SingleStarTest\\\\ClassicData.csv\"\n",
    "filenamep = \"C:\\\\Users\\\\oxfor\\\\Research\\\\rsadpy\\\\tests\\\\test_data\\\\SingleStarTest\\\\PAVOdata.csv\"\n",
    "filenamev = \"C:\\\\Users\\\\oxfor\\\\Research\\\\rsadpy\\\\tests\\\\test_data\\\\SingleStarTest\\\\Vegadata.csv\"\n",
    "filenamem = \"C:\\\\Users\\\\oxfor\\\\Research\\\\rsadpy\\\\tests\\\\test_data\\\\SingleStarTest\\\\MIRCX_June11162025_HD_219134.oifits\"\n",
    "filenamemy = \"C:\\\\Users\\\\oxfor\\\\Research\\\\rsadpy\\\\tests\\\\test_data\\\\SingleStarTest\\\\MYSTIC_June11162025_HD_219134.oifits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8feffe-a283-47d3-a0dc-591934414856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of brackets: 20\n",
      "Number of brackets: 1\n",
      "Number of brackets: 17\n",
      "Number of brackets: 36\n",
      "Number of brackets: 62\n"
     ]
    }
   ],
   "source": [
    "datav, num_brack_v = filename_extension(filenamev, 'V')\n",
    "datac, num_brack_c = filename_extension(filenamec, 'C')\n",
    "datap, num_brack_p = filename_extension(filenamep, 'P')\n",
    "datam, num_brack_m = filename_extension(filenamem, 'M')\n",
    "datamy, num_brack_my = filename_extension(filenamemy, 'My')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fc4de6e-d699-44a1-becb-f3d2c3d9c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "pavo_data = PavoData(datap)\n",
    "vega_data = VegaData(datav)\n",
    "classic_data = ClassicData(datac)\n",
    "mircx_data = MircxData(datam)\n",
    "mystic_data = MysticData(datamy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "002e9a3e-655c-4a2d-98d8-0d20cc0f8d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = mircx_data.make_df()\n",
    "df_my = mystic_data.make_df()\n",
    "df_p = pavo_data.make_df()\n",
    "df_v = vega_data.make_df()\n",
    "df_c = classic_data.make_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1de5506c-53c5-477b-87d6-5b6ffe375336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['Spf'] = df_p['B'] / df_p['Wave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ad9871-a5ba-4738-8f82-a8842b1a9a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b, v2, dv2, wave, band, brack, inst = combined(df_p, df_c, df_v, df_m, df_my)\n",
    "b, v2, dv2, wave, band, brack, inst = combined(df_p, df_c, df_v)\n",
    "#b, v2, dv2, wave, band, brack, inst = combined(df_m, df_my)\n",
    "spf = b/wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190df7eb-a812-495e-bc24-8860f7a9d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "star = StellarParams()\n",
    "p = 152.864\n",
    "dp = 0.0494\n",
    "f = 21.751\n",
    "df = 0.585\n",
    "logg = 4.5\n",
    "dlogg = 0.1\n",
    "m = 0.09\n",
    "dm = 0.08\n",
    "\n",
    "star.fbol = f\n",
    "star.fbol_err = df\n",
    "star.logg = logg\n",
    "star.logg_err = dlogg\n",
    "star.feh = m\n",
    "star.feh_err = dm\n",
    "star.plx = p\n",
    "star.plx_err = dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de355e17-dc86-46c0-b1fa-75d2be365daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Gaia DR3 ID: Gaia DR3 2009481748875806976\n",
      "Corrected parallax: 152.83842 [mas]\n",
      "Distance: 6.54286 +/- 0.00212 [pc]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oxfor\\anaconda3\\lib\\site-packages\\zero_point\\zpt.py:205: UserWarning: The apparent magnitude of one or more of the sources is outside the expected range (6-21 mag). \n",
      "                Outside this range, there is no further interpolation, thus the values at 6 or 21 are returned.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "D, dD = distances('HD 219134', verbose = True)\n",
    "star.dist = D\n",
    "star.dist_err = dD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2488c026-4085-4a08-aa7a-31a1289af63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling used\n",
      "Initial fit with lmfit:\n",
      "[[Model]]\n",
      "    Model(scaledUDV2)\n",
      "[[Fit Statistics]]\n",
      "    # fitting method   = leastsq\n",
      "    # function evals   = 22\n",
      "    # data points      = 461\n",
      "    # variables        = 2\n",
      "    chi-square         = 583.416313\n",
      "    reduced chi-square = 1.27105951\n",
      "    Akaike info crit   = 112.566872\n",
      "    Bayesian info crit = 120.833668\n",
      "    R-squared          = -60.2494576\n",
      "[[Variables]]\n",
      "    theta:  1.03857987 +/- 0.00267297 (0.26%) (init = 0.4)\n",
      "    V0:     1.00261510 +/- 0.00610421 (0.61%) (init = 1)\n",
      "[[Correlations]] (unreported correlations are < 0.100)\n",
      "    C(theta, V0) = +0.8778\n"
     ]
    }
   ],
   "source": [
    "results = initial_UDfit(spf, v2, dv2, 0.4, star, v0_flag = True, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c97fa222-ec97-42eb-8ebf-427c3f9ae745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0385798702807836,\n",
       " 0.0026729697848714715,\n",
       " 1.0026150959938753,\n",
       " 0.006104210284183727,\n",
       " 1.271059506336178)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c5b214e-00c2-457d-a825-6289d64d13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No scaling used\n"
     ]
    }
   ],
   "source": [
    "vals = udfit(df_p, star, v0_flag = False, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eb7f81f-44e7-412c-8f9b-e650d0379027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.036945441586439"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b73553-9277-4620-b30e-d51f5b17cedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta2, dtheta2, chisqr2 = initial_LDfit(spf, v2, dv2, star, 'R', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b23a79e5-9b19-474a-95c5-e612b8813e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling used\n",
      "Scaling used\n",
      "Scaling used\n",
      "Scaling used\n",
      "Scaling used\n",
      "Scaling used\n",
      "Scaling used\n",
      "Scaling used\n",
      "Scaling used\n"
     ]
    }
   ],
   "source": [
    "#theta_results = run_UDfit(71, 71, datasets = [pavo_data, vega_data, classic_data, mircx_data, mystic_data], \n",
    "#                                      stellar_params = star)\n",
    "theta_results = run_UDfit(2, 2, datasets = [pavo_data, vega_data, classic_data], \n",
    "                                      stellar_params = star, v0_flag = True)\n",
    "#theta_results = run_UDfit(71, 71, datasets = [mircx_data, mystic_data], \n",
    "#                                      stellar_params = star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06080d6f-3c74-4a73-b0de-b65f1085db58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0228916197065379,\n",
       " 1.0295057584062353,\n",
       " 1.0333027447183847,\n",
       " 1.0222377825241653]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "458bee7c-fa46-4872-ab0f-8dc1143d9ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Disk Diameter after MC/BS: 1.027 +/- 0.00539 mas\n",
      "V0^2: 0.96185 +/- 0.00011\n",
      "Chi-squared: 20.397\n",
      "Chi-squared reduced: 0.044\n",
      "Temperature: 4988.7 +/- 36.0 K\n"
     ]
    }
   ],
   "source": [
    "udfit_values(spf, v2, dv2, theta_results, stellar_params = star, v0_flag = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf59970-63ac-4c81-87b9-081c0fdc87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thetaf, dthetaf, tf, dtf, ldcsf, chisf = run_LDfit(71, 71, ogdata = [spf, v2, dv2], \n",
    "#                                                                 datasets = [pavo_data, vega_data, classic_data, mircx_data, mystic_data], \n",
    "#                                                                 stellar_params = star, verbose = True)\n",
    "thetaf, dthetaf, tf, dtf, ldcsf, chisf = run_LDfit(71, 71, ogdata = [spf, v2, dv2], \n",
    "                                                                 datasets = [pavo_data, vega_data, classic_data], \n",
    "                                                                 stellar_params = star, verbose = True)\n",
    "#thetaf, dthetaf, tf, dtf, ldcsf, chisf = run_LDfit(71, 71, ogdata = [spf, v2, dv2], \n",
    "#                                                                datasets = [mircx_data, mystic_data], \n",
    "#                                                                 stellar_params = star, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ea753-785c-4ed3-b3f4-c79c03d9d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_star_params(star, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca433cb-ea98-4c88-8d44-df6ab711b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'pavo':pavo_data, 'vega':vega_data, 'classic':classic_data}\n",
    "#data_dict = {'mircx':mircx_data,'mystic':mystic_data}\n",
    "#data_dict = {'pavo':pavo_data, 'vega':vega_data, 'classic':classic_data, 'mircx':mircx_data,'mystic':mystic_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20215ae-fcac-4057-b9d5-122df501cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_v2_fit(\n",
    "    data_dict=data_dict,\n",
    "    star=star,        \n",
    "    datasets_to_plot=['pavo', 'classic', 'vega'],\n",
    "    to_bin = ['pavo'],\n",
    "    plot_udmodel = True,\n",
    "    title = rf'$\\rm HD~219134$',\n",
    "    #set_axis= [-0.05, 5e8, -0.05, 1.1],\n",
    "    eq_text=True,\n",
    "    show = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed723d-a1b4-4ab9-976d-1be7f87f2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_v2_fit(\n",
    "    data_dict=data_dict,\n",
    "    star=star,        \n",
    "    datasets_to_plot=['pavo', 'classic', 'vega'],\n",
    "    to_bin = ['pavo'],\n",
    "    ldc_band = 'ldc_K',\n",
    "    plot_ldmodel = True,\n",
    "    title = rf'$\\rm HD~219134$',\n",
    "    #set_axis= [-0.05, 5e8, -0.05, 1.1],\n",
    "    eq_text=True,\n",
    "    show = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b157c3b-31d6-4190-b343-312decbcf8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
